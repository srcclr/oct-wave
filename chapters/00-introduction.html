
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Introduction Â· GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="HonKit 3.4.0">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="01-automated-test-case-generation.html" />
    
    
    <link rel="prev" href="../" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Preface
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.2" data-path="00-introduction.html">
            
                <a href="00-introduction.html">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="01-automated-test-case-generation.html">
            
                <a href="01-automated-test-case-generation.html">
            
                    
                    Beyond Unit Tests: Automated Test Case Generation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="02-property-based-testing.html">
            
                <a href="02-property-based-testing.html">
            
                    
                    Beyond Unit Tests: Property-based Testing
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="04-functional.html">
            
                <a href="04-functional.html">
            
                    
                    Execute Your User Stories!
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="05-where-is-my-casette.html">
            
                <a href="05-where-is-my-casette.html">
            
                    
                    Where is my cassette? Mocking system testing using capture and replay
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="06-contract.html">
            
                <a href="06-contract.html">
            
                    
                    Contract testing with Pact
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8" >
            
                <span>
            
                    
                    Test Containers
            
                </span>
            

            
        </li>
    
        <li class="chapter " data-level="1.9" data-path="10-cypress.html">
            
                <a href="10-cypress.html">
            
                    
                    E2E with Cypress
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10" data-path="09-monitoring.html">
            
                <a href="09-monitoring.html">
            
                    
                    Monitoring as Testing
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11" data-path="07-update-advisor.html">
            
                <a href="07-update-advisor.html">
            
                    
                    Proof Pearl: On the Correctness of Update Advisor
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12" data-path="13-grammar.html">
            
                <a href="13-grammar.html">
            
                    
                    GramTest: a tool for grammar-based test case generation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.13" data-path="08-symbolic.html">
            
                <a href="08-symbolic.html">
            
                    
                    Dynamic Symbolic Execution with Pathgrind
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.14" data-path="09-efda.html">
            
                <a href="09-efda.html">
            
                    
                    EFDA: a benchmark for software composition analysis tools
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.15" >
            
                <span>
            
                    
                    Perspectives
            
                </span>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://github.com/honkit/honkit" target="blank" class="gitbook-link">
            Published with HonKit
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Introduction</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="introduction">Introduction</h1><p>Shipping code fast is key to delivering a successful software product. First-mover advantage is critical in many domains, and with the easy availability of cloud infrastructure, open source components, and CI/CD practices and tools, it&apos;s never been more possible to go fast.</p><p>However, increasing speed at the cost of everything else (&quot;move fast and break things&quot;) is untenable beyond a certain point. When shortcuts are taken, tech debt accumulates, slowing development over time. Furthermore, the occasional bug or incident must be tolerable -- a non-starter in domains where availability is paramount, e.g. cloud infrastructure, or application security products.</p><p>This seems at first glance like a fundamental tradeoff, but doesn&apos;t have to be: if processes and tools evolve to support rapid development, we <em>can</em> maintain quality while shipping on time. The key is being extremely deliberate with our testing efforts and continuously optimizing them for efficiency.</p><h1 id="effective-and-efficient-testing">Effective and Efficient Testing</h1><p>Traditional software development models rely heavily on black box integration (or <em>system</em>) testing: running test cases against live instances of the application with real databases attached, usually in some sort of staging environment.</p><p>Indicators that this is the case include having dedicated &quot;QA engineers&quot; who spend most of their time writing tests, the use of a test case management system, or there being a special testing phase, usually occurring after development on a feature is done and before release.</p><p>This isn&apos;t a bad thing in itself, but it does reveal that testing is seen as something separate from the development process. Is <em>this</em> a bad thing?</p><p>The following histogram, taken from a study<sup><a href="#fn_1" id="reffn_1">1</a></sup> on software quality metrics, shows the distribution of bugs across 114 projects and the phase of development in which they were identified.</p><p><img alt="ineffectiveness of testing" src="../images/intro1.png"></p><p>Of note is the low <em>effectiveness</em> of system testing; most bugs were detected via other means, <em>throughout development</em>.</p><p>Later in the paper, we see a plot of bugfix time by development phase.</p><p><img alt="inefficiency of testing" src="../images/intro2.png"></p><p>It is also significantly less <em>efficient</em> to fix a bug past the development phase due to the overhead involved. Testing late is prohibitively expensive:</p><blockquote><p>The difficulty is that a system must be tested, unexpected results logged in the bug-tracking system, the issue must be assigned, the actual source of the fault must be identified before the problem can be corrected, and finally the fix must be retested. High [bugfix] yields are only possible when there are very few defects entering late test since high defect rates would overwhelm the capacity to execute the find, fix it, and retest.</p></blockquote><p>Whereas if a bug were found via a unit test, a developer could fix it in minutes and move on.</p><p>A conclusion we can draw from this is that testing <em>has</em> to be interleaved with development if we are to get a significant quality yield from it. Quality cannot be &quot;tested in&quot; at the end; it is an integral part and consequence of the development process.</p><p>This is not to say that integration testing should not be used. It can be useful as a sanity check (in the form of smoke tests), but there is little reason to use it as the primary form of testing. Unit testing is vastly more effective at finding some kinds of bugs (e.g. errors in method-level specifications), and being significantly cheaper than integration testing, it should be used whenever it suffices; at the same time, it should not be used to the exclusion of other techniques (e.g. exclusively doing TDD). This argument can be made for most of the <a href="https://en.wikipedia.org/wiki/Software_testing#Testing_types,_techniques_and_tactics" target="_blank">multitude of testing techniques</a> in use today. In fact, the more diverse our testing strategy, the more mileage we&apos;re likely to get out of it.</p><p>In this book, we cover a number of these techniques, including:</p><ul><li><strong>Extensions to unit testing</strong>: property-based testing and test case generation
</li>
<li><strong>Lightweight integration testing</strong>: functional testing/BDD, contract testing, regression testing
</li>
<li><strong>Integration testing</strong>: tools for writing them more correctly and efficiently
</li>
<li><strong>Exhaustive testing</strong>: fuzzing, proving correctness
</li></ul>
<h1 id="quality-as-availability">Quality as Availability</h1><p>Users experience the robustness of a system through its availability, which is typically characterized by two metrics:</p><ul><li>The <em>mean time between failures</em> (MTBF) is the average amount of a time the system is able to function correctly for. It measures how reliable the system is.
</li>
<li>The <em>mean time to repair</em> (MTTR) measures the average amount of downtime. It also serves as a proxy for how reactive the team is to failures and how efficiently they are resolved.
</li></ul>
<p>Availability (or uptime) is thus</p><p>$$Availability = \frac{MTBF}{MTBF + MTTR}$$</p><p>For example, if a system fails every 10 hours for 15 minutes each time on average, its availability would be $\frac{10}{10+0.25}=97.6\%$.</p><p>How does this relate to testing? <em>Testing is only ever able to increase MTBF</em>. No amount of testing can <em>prevent</em> a system from going down or shorten the amount of time it spends broken. We&apos;re reminded of Dijkstra&apos;s well-known quote:</p><blockquote><p>Program testing can be used to show the presence of bugs, but never to show their absence!</p></blockquote><p>This means that beyond a certain point, testing will not increase availability.</p><p><img alt="achieving high availability" src="../images/intro3.png"></p><p>For the given MTTR values, as MTBF increases, even to the extent of years, the graphs all converge and availability stops increasing.
If we want to achieve <a href="https://en.wikipedia.org/wiki/High_availability#Percentage_calculation" target="_blank">high availability</a>, we need <em>monitoring</em> in addition to testing, to reduce MTTR -- ways to find or react to bugs, not just check for them.</p><p>A corollary to this is that exhaustive testing or optimizing for coverage isn&apos;t the most cost efficient use of time for availability. Given that there is <a href="https://www.bitlog.com/2020/02/12/why-are-we-so-bad-at-software-engineering/" target="_blank">very limited</a> time for software quality in general, we have to be very careful how we spend it.</p><h1 id="testing--monitoring">Testing + Monitoring</h1><p>The approach to testing we outlined is often referred to as &quot;Shifting Left&quot;, in reference to the waterfall diagram we know and love.</p><p><img alt="waterfall" src="../images/waterfall.png"></p><p>The idea is to move testing to the left, to an earlier stage in the development process.</p><p>In striving to reduce MTTR and pursue greater levels of availability, we might suggest Shifting Right as well, past the deployment phase, when we implement a monitoring strategy. This would include:</p><ul><li><strong>Ways to deploy more robustly</strong>: atomic deployments, <a href="https://aws.amazon.com/builders-library/automating-safe-hands-off-deployments/" target="_blank">automated rollbacks</a>
</li>
<li><strong>Ways to find bugs</strong>: <a href="https://netflix.github.io/chaosmonkey/" target="_blank">chaos engineering</a>
</li>
<li><strong>Ways to contain blast radius</strong>: feature flags, dark releases, canary deployments, circuit breaking
</li>
<li><strong>Ways to be alerted faster</strong>: metrics, alarms
</li></ul>
<p>Implementing these competently makes it possible for us to have both high quality and speed.</p><h1 id="principles">Principles</h1><p>In conclusion, here are the principles of our approach.</p><h2 id="complete-automation-over-manual-testing">Complete automation over manual testing</h2><ul><li>Deployments and infrastructure should be fully automated and transparent
</li>
<li>Any engineer on the team should be able to deploy
</li>
<li>Automated quality gates (static analysis, security scans, passing tests) should be kept relevant
</li>
<li>Break builds to uphold standards
</li>
<li>Constant reevaluation of pipeline speed and quality gate relevance
</li>
<li>No manual testing
</li>
<li>No manual gatekeeping (except for code review)
</li></ul>
<h2 id="early-error-detection-over-end-to-end-testing">Early error detection over end-to-end testing</h2><ul><li>Quality cannot be &quot;tested in&quot;
</li>
<li>Testing must be interleaved with development
</li>
<li>An ensemble of testing techniques is more effective and efficient
</li>
<li>All developers are involved in writing and maintaining tests
</li></ul>
<h2 id="monitoring-and-recovery-over-exhaustive-testing">Monitoring and recovery over exhaustive testing</h2><ul><li>Testing only increases MTBF, which cannot increase availability beyond a certain point
</li>
<li>Reducing MTTR via monitoring is required for high availability
</li>
<li>Exhaustive testing isn&apos;t a cost efficient way to increase quality
</li></ul>
<h2 id="increasing-confidence-in-delivery-over-bug-finding">Increasing confidence in delivery over bug finding</h2><p>To quote <a href="https://www.drmaciver.com/2018/04/some-of-my-problems-with-correctness-research/" target="_blank">John Regehr</a>:</p><blockquote><p>The market for software, generally speaking, does not reward correct software so much as software that is acceptably correct and that can be built cheaply and rapidly. Thus, while our work on software correctness is highly unlikely to improve the quality of software, it may plausibly make it possible to create acceptable software a bit more cheaply and rapidly.</p></blockquote><p>No amount of testing can show that a system is free of bugs. However, the purpose of testing in a commercial software environment is not to produce flawless software, but to increase confidence in delivery: to give us assurance that our software can not only evolve correctly, but work correctly in the hands of real users.</p><p>To that end, we employ the same methods and tools and strive towards the same ideals, but are willing to compromise rigor when that would impede delivery.</p>
                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="../" class="navigation navigation-prev " aria-label="Previous page: Preface">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="01-automated-test-case-generation.html" class="navigation navigation-next " aria-label="Next page: Beyond Unit Tests: Automated Test Case Generation">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Introduction","level":"1.2","depth":1,"next":{"title":"Beyond Unit Tests: Automated Test Case Generation","level":"1.3","depth":1,"path":"chapters/01-automated-test-case-generation.md","ref":"chapters/01-automated-test-case-generation.md","articles":[]},"previous":{"title":"Preface","level":"1.1","depth":1,"path":"preface.md","ref":"preface.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["mathjax"],"pluginsConfig":{"mathjax":{},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"preface.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}}},"file":{"path":"chapters/00-introduction.md","mtime":"2021-03-10T03:55:43.063Z","type":"markdown"},"gitbook":{"version":"3.4.0","time":"2021-03-10T03:56:33.636Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-mathjax/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

